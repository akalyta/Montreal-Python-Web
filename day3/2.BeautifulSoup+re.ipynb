{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Python Regular Expressions and BeautifulSoup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** by Radhika Saksena <br/>\n",
      "Princeton University <br/>\n",
      "saksena@princeton.edu, radhika.saksena@gmail.com**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Disclaimer: The code examples presented in this and subsequent handouts are for educational purposes only. Please seek advice from a legal expert about the legal implications of using this code for web scraping.\n",
      "**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. A Motivating Example"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1.1. Ex: Hurricane Sandy Relief Bill"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "* To demonstrate the ``BeautifulSoup`` + ``re`` concepts, we'll use the Hurricane Sandy relief bill which was enacted by the 113-th U.S. Congress. This bill, along with associated meta-data, is available as an XML document at https://www.govtrack.us/data/congress/113/bills/hr/hr41/data.xml.  \n",
      "\n",
      "\n",
      "* Note that http://govtrack.us is a rich source of machine-readable data on bills, roll calls and more from the current Congress as well as past U.S. Congresses.\n",
      "\n",
      "\n",
      "* Let's inspect this XML document. A snippet of the XML document is also listed below for quick reference."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "<bill session=\"113\" type=\"h\" number=\"41\" updated=\"2014-05-31T06:21:27-04:00\">\n",
      "    <state datetime=\"2013-01-06\">ENACTED:SIGNED</state>\n",
      "    <status>\n",
      "        <unknown datetime=\"2013-01-06\"/>\n",
      "    </status>\n",
      "    <introduced datetime=\"2013-01-03\"/>\n",
      "    <titles>\n",
      "        <title type=\"popular\">Hurricane Sandy relief bill</title>\n",
      "        <title type=\"official\" as=\"introduced\">\n",
      "            To temporarily increase the borrowing authority of the Federal Emergency Management Agency for carrying out the National Flood Insurance Program.\n",
      "        </title>\n",
      "    </titles>\n",
      "    <sponsor id=\"400145\"/>\n",
      "    <cosponsors>...</cosponsors>\n",
      "    <actions>...</actions>\n",
      "    <committees>\n",
      "        <committee code=\"HSBA\" name=\"House Financial Services\" activity=\"Referral\"/>\n",
      "        <committee code=\"HSBU\" name=\"House Budget\" activity=\"Referral\"/>\n",
      "    </committees>\n",
      "    <relatedbills/>\n",
      "    <subjects>\n",
      "        <term name=\"Emergency management\"/>\n",
      "        <term name=\"Budget process\"/>\n",
      "        <term name=\"Department of Homeland Security\"/>\n",
      "        <term name=\"Disaster relief and insurance\"/>\n",
      "        <term name=\"Executive agency funding and structure\"/>\n",
      "        <term name=\"Federal Emergency Management Agency (FEMA)\"/>\n",
      "        <term name=\"Floods and storm protection\"/>\n",
      "    </subjects>\n",
      "    <amendments/>\n",
      "    <summary>\n",
      "        1/6/2013--Public Law. Amends the National Flood Insurance Act of 1968 to increase from $20.725 billion to $30.425 billion the total amount of notes and obligations (federal borrowing authority) which may be issued by the Administrator of the Federal Emergency Management Agency (FEMA), with the President's approval, for the National Flood Insurance program. Designates such increase as an emergency requirement under the the Statutory Pay-As-You-Go Act of 2010.\n",
      "    </summary>\n",
      "</bill>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2. Combining Python Regex and ``BeautifulSoup``"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* BeautifulSoup's ``find()`` and ``find_all()`` methods can be augmented with Python's regular expressions to achieve different types of HTML/XML parsing tasks, such as, searching for tags/attributes/text that match a particular **pattern** rather than merely matching a string. We'll go over this functionality with some examples."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2.1. Find tags matching a pattern. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Let's assume that our task is to extract the IDs of all the bill sponsors (marked up by the `<sponsor>` tag) and\n",
      "all the bill co-sponsors (marked up by the `<cosponsor>` tag) who are listed in the XML document.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "* We have already seen how to specify the tag\u2019s name as an argument to BeautifulSoup's ``find_all()`` method. We know that, on finding one or more matches, the ``find_all()`` method returns the corresponding tag object(s) in a list. However, in our present task, we'd like to match multiple tags - `<sponsor>` and `<cosponsor>`. So, instead of specifying a tag\u2019s name, we'll need to specify a **pattern**:``.*sponsor$`` - which will be used by ``find_all()`` to find tag objects of interest.\n",
      "\n",
      "\n",
      "* Note the use of ``$`` sign in the pattern above. This special character signi\ufb01es the end of the string. It is required in the regex pattern to ensure that the pattern does not match the `<cosponsors>` tag object. The `<cosponsors> `tag object does not have an id attribute and is merely a container for the list of `<cosponsor>` tag objects.\n",
      "\n",
      "\n",
      "* Once we have the list of relevant sponsor/cosponsor tag objects, we can extract\n",
      "the id attribute from each of them. The code listing below shows how to do this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "URL = \"https://www.govtrack.us/data/congress/113/bills/hr/hr41/data.xml\"\n",
      "XMLStr = urllib2.urlopen(URL).read()\n",
      "soup = BeautifulSoup(XMLStr)\n",
      "\n",
      "#more concise with re\n",
      "sponsors = soup.find_all(re.compile(\"sponsor$\"))\n",
      "\n",
      "for sponsor in sponsors[:10]:\n",
      "    print(sponsor.get(\"id\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "400145\n",
        "400008\n",
        "400031\n",
        "412221\n",
        "412563\n",
        "412193\n",
        "400087\n",
        "400103\n",
        "400122\n",
        "412524\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2.2. Find attributes matching a pattern."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Suppose, our task was to inspect the Hurricane Sandy Relief bill document to determine whether particular legislators were involved in the legislation.\n",
      "\n",
      "\n",
      "\n",
      "*  A straightforward way to do this would be to check if there are any tags whose ID attribute matches the legislators\u2019 ID.\n",
      "\n",
      "\n",
      "*  In the following code, we check whether the string ``400031`` or ``412319`` appear as a value for the ``id`` attribute and if either/both of these values do appear, the corresponding tag objects are printed out as strings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "URL = \"https://www.govtrack.us/data/congress/113/bills/hr/hr41/data.xml\"\n",
      "XMLStr = urllib2.urlopen(URL).read()\n",
      "soup = BeautifulSoup(XMLStr)\n",
      "\n",
      "tagObjs = soup.find_all(id=re.compile(\"400031|412319\"))\n",
      "\n",
      "for tagObj in tagObjs:\n",
      "    print(tagObj)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<cosponsor id=\"400031\" joined=\"2013-01-03\"></cosponsor>\n",
        "<cosponsor id=\"412319\" joined=\"2013-01-03\"></cosponsor>\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2.3. Find tags and attributes matching specific patterns"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Let\u2019s say that we are given multiple XML documents corresponding to di\ufb00erent bills. And we are interested in selecting those bills that are sponsored (not co-sponsored) by the legislator whose govtrack ID is ``412276`` (Alan Grayson [D-FL-9], who is one of the more proli\ufb01c sponsors of bills in the 113-th Congress).\n",
      "\n",
      "\n",
      "* In this case, we'll invoke BeautifulSoup's ``find_all()`` method by specifying *both* the tag name (which is ``sponsor``) **and** specifying the tag's ``id`` attribute (``id`` should be equal to 412276). \n",
      "\n",
      "\n",
      "* Both conditions need to be specified in ``find_all()``. This is because, the ``co-sponsor`` tag also has an ``id`` attribute. And so, if the `<sponsor>` tag is omitted in the call to ``find_all()``, then BeautifulSoup will return a positive match for bills on which the legislator ID 412276 is also a co-sponsor - this is not what we want.\n",
      "\n",
      "\n",
      "* In the following code, a given XML file is examined to determine whether the bill was sponsored by the legislator whose id is 412276 and an appropriate message is printed to screen. This code can easily be extended to run on multiple XML documents corresponding to di\ufb00erent bills. Bill documents from the current and past U.S. Congresses are available at https://www.govtrack.us/data/congress/ in XML format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re, os\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "URL = \"https://www.govtrack.us/data/congress/113/bills/hr/hr3737/data.xml\"\n",
      "soup = BeautifulSoup(urllib2.urlopen(URL).read())\n",
      "\n",
      "sponsorTag = soup.find(\"sponsor\",id=re.compile(\"412276\"))\n",
      "\n",
      "if sponsorTag:\n",
      "    billNum = soup.bill.get(\"number\")\n",
      "    billName = soup.find(\"title\",type=\"official\")\n",
      "    print(\"This Bill was sponsored by legislator ID 412776.\")\n",
      "    print(\"Bill Number = %s \\nBill Title = %s\" % (billNum,billName.text))\n",
      "else:\n",
      "    print(\"Bill not sponsored by legislator ID 412276.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This Bill was sponsored by legislator ID 412776.\n",
        "Bill Number = 3737 \n",
        "Bill Title = To amend title XVIII of the Social Security Act to provide for an option for any citizen or permanent resident of the United States to buy into Medicare.\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2.4. Find text matching a pattern"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In this example, our task is to pick out all the HTML elements (or in ``BeautifulSoup`` terminology: tag objects) in which the text includes words that are derivatives of `\"consider\"`, such as `\"consideration\"`, `\"reconsider\"`, etc. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import re\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "URL = \"https://www.govtrack.us/data/congress/113/bills/hr/hr41/data.xml\"\n",
      "XMLStr = urllib2.urlopen(URL).read()\n",
      "\n",
      "soup = BeautifulSoup(XMLStr)\n",
      "\n",
      "# this doesn\u2019t work\n",
      "#results = soup.find_all(text=\"consider\")\n",
      "\n",
      "results = soup.find_all(text=re.compile(\"consider\",re.IGNORECASE))\n",
      "\n",
      "print(\"\\nMatches for \\\"consider\\\" and it\u2019s derivatives are: \\n\")\n",
      "for i in range(0,len(results)):\n",
      "    print(\"%d. %s\\n\" % (i+1,results[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Matches for \"consider\" and it\u2019s derivatives are: \n",
        "\n",
        "1. Referred to the Committee on Financial Services, and in addition to the Committee on the Budget, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned.\n",
        "\n",
        "2. Considered under suspension of the rules.\n",
        "\n",
        "3. Motion to reconsider laid on the table Agreed to without objection.\n",
        "\n",
        "4. Received in the Senate, read twice, considered, read the third time, and passed without amendment by Voice Vote.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Here, we've used ``BeautifulSoup.find_all()`` in conjunction with the ``re.compile()`` to pick out these tag objects. If we just tried to match the string `\"consider\"` to the text in the XML, this wouldn't work because the string `\"consider\"` only occurs in its derivative forms in the XML document. So it's necessary to use pattern matching here in contrast to just simply comparing strings.\n",
      "\n",
      "\n",
      "\n",
      "* Note that specifying the `text` option to ``find_all()`` results in a list of text elements being returned on a successful match. This is different from specifying tags or attributes to `` find_all `` where tag objects are returned."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
