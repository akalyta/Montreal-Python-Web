{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Exercise: Federalist Papers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "**Workshop on Web Scraping and Text Processing with Python**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**by Radhika Saksena, Princeton University, saksena@princeton.edu, radhika.saksena@gmail.com**\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Disclaimer: The code examples presented in this and subsequent handouts are for educational purposes only. Please seek advice from a legal expert about the legal implications of using this code for web scraping.\n",
      "*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At http://thomas.loc.gov/home/histdox/fedpapers.html, you will find a list of links to HTML pages containing text of the Federalist papers. The links are listed in an HTML table with the columns containing the index, title, author and publication date of each Federalist paper. A snippet of the HTML document is shown below for quick reference."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " <table class=\"laws\">\n",
      "    <tbody><tr> \n",
      "      <th scope=\"col\" width=\"5%\"><p><strong>No.</strong></p></th>\n",
      "      <th scope=\"col\" width=\"40%\"><p><strong>Title</strong></p></th>\n",
      "      <th scope=\"col\"><p><strong>Author</strong></p></th>\n",
      "      <th scope=\"col\" width=\"30%\"><p><strong>Publication</strong></p></th>\n",
      "      <th scope=\"col\" width=\"25%\"><p><strong>Date</strong></p></th>\n",
      "\n",
      "    </tr>\n",
      "    <tr> \n",
      "      <td width=\"5%\"><p> \n",
      "        <strong>1</strong></p></td>\n",
      "      <td width=\"40%\"><p><a href=\"fed_01.html\">General Introduction</a></p></td>\n",
      "      <td><p>Hamilton</p></td>\n",
      "      <td width=\"30%\"><p>For the Independent Journal</p></td>\n",
      "\n",
      "       <td width=\"25%\"><p>- -</p></td>\n",
      "    </tr>\n",
      "    <tr> \n",
      "      <td width=\"5%\"><p> \n",
      "        <strong>2</strong></p></td>\n",
      "      <td width=\"40%\"><p><a href=\"fed_02.html\">Concerning Dangers from Foreign Force and Influence</a></p></td>\n",
      "      <td><p>Jay</p></td>\n",
      "\n",
      "      <td width=\"30%\"><p>For the Independent Journal</p></td>\n",
      "       <td width=\"25%\"><p>- -</p></td>\n",
      "    </tr>\n",
      "    ...\n",
      "     <tr> \n",
      "      <td width=\"5%\"><p><strong>85</strong></p></td>\n",
      "      <td width=\"40%\"><p><a href=\"fed_85.html\">Concluding Remarks</a></p></td>\n",
      "      <td><p>Hamilton</p></td>\n",
      "      <td width=\"30%\"><p>From McLEAN's Edition, New York</p></td>\n",
      "       <td width=\"25%\"><p>- -</p></td>\n",
      "    </tr>\n",
      "  </tbody></table>\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2. Task: Extract the Federalist papers table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Extract the content in the table of Federalist papers at http://thomas.loc.gov/home/histdox/fedpapers.html. Store the content in a ``pandas`` DataFrame and save it to local disk as a CSV file.**"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "\n",
      "# initialize URL and baseURL strings\n",
      "URL = \"http://thomas.loc.gov/home/histdox/fedpapers.html\"\n",
      "baseURL = \"http://thomas.loc.gov/home/histdox/\"\n",
      "\n",
      "# initialize pandas DataFrame for storing extracted content\n",
      "colNames = [\"no.\",\"title\",\"link\",\"author\",\"publication\",\"date\"]\n",
      "df = pd.DataFrame(columns=colNames)\n",
      "\n",
      "# create a BeautifulSoup object from the HTML document\n",
      "soup = BeautifulSoup(urllib2.urlopen(URL).read())\n",
      "\n",
      "# find the table in the HTML document\n",
      "tableObj = soup.find(\"table\")\n",
      "\n",
      "# find all the rows in the table\n",
      "rows = tableObj.find_all(\"tr\")\n",
      "\n",
      "# iterate over all rows except the first\n",
      "for row in rows[1:]:\n",
      "    # extract column text from each row and save in DataFrame\n",
      "    cols = row.find_all(\"td\")\n",
      "    df = df.append({\"no.\":cols[0].text.strip(),\n",
      "               \"title\":cols[1].text.strip(),\n",
      "               \"link\":cols[1].a.get(\"href\"),\n",
      "               # \"link\":cols[1].find(\"a\").get(\"href\"),\n",
      "               \"author\":cols[2].text.strip(),\n",
      "               \"publication\":cols[3].text.strip(),\n",
      "               \"date\":cols[4].text.strip()},\n",
      "                  ignore_index=True)\n",
      "df.to_csv(\"federalistTable.csv\",sep=\",\",index=False)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 10 federalistTable.csv"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no.,title,link,author,publication,date\r\n",
        "1,General Introduction,fed_01.html,Hamilton,For the Independent Journal,- -\r\n",
        "2,Concerning Dangers from Foreign Force and Influence,fed_02.html,Jay,For the Independent Journal,- -\r\n",
        "3,\"The Same Subject Continued:\r",
        "\r\n",
        "\r",
        "\r\n",
        "\r",
        "\r\n",
        "        Concerning Dangers from Foreign Force and Influence\",fed_03.html,Jay,For the Independent Journal,- -\r\n",
        "4,\"The Same Subject Continued:\r",
        "\r\n",
        "\r",
        "\r\n",
        "        Concerning Dangers from Foreign Force and Influence\",fed_04.html,Jay,For the Independent Journal,- -\r\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "* The space/newline characters from the HTML page are affecting the formatting of the table. So let's write a utility function ``replaceSpaces`` to improve the formatting. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replaceSpaces(htmlTxt):\n",
      "    '''This function uses the string replace method\n",
      "    to replace all occurrences of the space \n",
      "    characters in replaceList with a single space.'''\n",
      "    \n",
      "    replaceList=[\"\\t\",\"\\r\",\"\\n\"]\n",
      "    toStr = \" \"\n",
      "    \n",
      "    for fromStr in replaceList:\n",
      "        htmlTxt = htmlTxt.replace(fromStr,toStr)\n",
      "    return htmlTxt\n",
      "\n",
      "\n",
      "# a better replaceSpaces() fn which uses the re module\n",
      "import re\n",
      "def replaceSpaces2(htmlTxt):\n",
      "    '''This function uses the re module method\n",
      "    to replace all occurrences of the space \n",
      "    characters in replaceList with a single space.'''\n",
      "    \n",
      "    replaceList=[r\"\\s+\",r\"\\t+\",r\"\\r+\",r\"\\n+\"]\n",
      "    toStr = \" \"\n",
      "    \n",
      "    for fromStr in replaceList:\n",
      "        htmlTxt = re.sub(fromStr,toStr,htmlTxt)\n",
      "    return htmlTxt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "* Now let's use this ``replaceSpaces()`` function in our earlier code to extract the Federalist papers table. (Or try the ``replacesSpaces2() function`` which uses Python's `re` module and produces better formatting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "\n",
      "# initialize URL and baseURL strings\n",
      "URL = \"http://thomas.loc.gov/home/histdox/fedpapers.html\"\n",
      "baseURL = \"http://thomas.loc.gov/home/histdox/\"\n",
      "\n",
      "# initialize pandas DataFrame for storing extracted content\n",
      "colNames = [\"no.\",\"title\",\"link\",\"author\",\"publication\",\"date\"]\n",
      "df = pd.DataFrame(columns=colNames)\n",
      "\n",
      "# create a BeautifulSoup object from the HTML document\n",
      "soup = BeautifulSoup(urllib2.urlopen(URL).read())\n",
      "\n",
      "# find the table in the HTML document\n",
      "tableObj = soup.find(\"table\")\n",
      "\n",
      "# find all the rows in the table\n",
      "rows = tableObj.find_all(\"tr\")\n",
      "\n",
      "# iterate over all rows except the first\n",
      "for row in rows[1:]:\n",
      "    # extract column text from each row and save in DataFrame\n",
      "    cols = row.find_all(\"td\")\n",
      "    df = df.append({\"no.\":replaceSpaces(cols[0].text),\n",
      "               \"title\":replaceSpaces(cols[1].text),\n",
      "               \"link\":cols[1].a.get(\"href\"),\n",
      "               # \"link\":cols[1].find(\"a\").get(\"href\"),\n",
      "               \"author\":replaceSpaces(cols[2].text),\n",
      "               \"publication\":replaceSpaces(cols[3].text),\n",
      "               \"date\":replaceSpaces(cols[4].text)},\n",
      "                  ignore_index=True)\n",
      "\n",
      "df.to_csv(\"federalistTable.csv\",sep=\",\",index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 10 federalistTable.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no.,title,link,author,publication,date\r\n",
        " 1,General Introduction,fed_01.html,Hamilton,For the Independent Journal,- -\r\n",
        " 2,Concerning Dangers from Foreign Force and Influence,fed_02.html,Jay,For the Independent Journal,- -\r\n",
        "3,The Same Subject Continued:              Concerning Dangers from Foreign Force and Influence,fed_03.html,Jay,For the Independent Journal,- -\r\n",
        "4,The Same Subject Continued:            Concerning Dangers from Foreign Force and Influence,fed_04.html,Jay,For the Independent Journal,- -\r\n",
        "5,The Same Subject Continued:            Concerning Dangers from Foreign Force and Influence,fed_05.html,Jay,For the Independent Journal,- -\r\n",
        "6,Concerning Dangers from Dissensions Between the           States,fed_06.html,Hamilton,For the Independent Journal,- -\r\n",
        "7,The Same Subject Continued:            Concerning Dangers from Dissensions Between the States,fed_07.html,Hamilton,For the Independent Journal,- -\r\n",
        "8,The Consequences of Hostilities Between the States,fed_08.html,Hamilton,From the New York Packet,\"Tuesday, November 20, 1787\"\r\n",
        "9,The Union as a Safeguard Against Domestic Faction           and Insurrection,fed_09.html,Hamilton,For the Independent Journal,- -\r\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "3. Task: Download the Federalist Papers as HTML documents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Follow each of the links listed in the table of Federalist papers at http://thomas.loc.gov/home/histdox/fedpapers.html. The links will take you to each Federalist paper's HTML page. Download the HTML pages for all the Federalist papers and store them to local disk.**"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# iterate over Federalist paper links\n",
      "for i,row in df.iterrows():\n",
      "    \n",
      "    # construct the URL to fetch and local file name\n",
      "    link = baseURL + row[\"link\"]\n",
      "    HTMLFile = row[\"link\"]\n",
      "\n",
      "    # download the HTML file\n",
      "    print(\"Downloading file \" + HTMLFile + \"...\")\n",
      "    HTMLStr = urllib2.urlopen(link).read()                                    \n",
      "    \n",
      "    # write the HTML file to local disk\n",
      "    with open(HTMLFile,\"w\") as fout:\n",
      "        fout.write(HTMLStr)\n",
      "    \n",
      "    print(\"Completed downloading file \" + HTMLFile + \".\")"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "4. Task: Extract and Save Text from the Federalist Papers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Now that you know how to access the HTML page for each individual Federalist paper. Use ``BeautifulSoup`` to extract the text of the papers and store them in text files on your local computer.**"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# iterate over Federalist paper links\n",
      "for i,row in df.iterrows():\n",
      "    \n",
      "    # construct the URL to fetch and local file name\n",
      "    link = baseURL + row[\"link\"]\n",
      "    txtFile = row[\"link\"] + \".txt\"\n",
      "\n",
      "    print(\"Processing file \" + txtFile + \"...\")                                 \n",
      "    \n",
      "    # fetch the link and construct soup object from the response\n",
      "    paperSoup = BeautifulSoup(urllib2.urlopen(link).read())  \n",
      "    \n",
      "    # write the extracted to text file\n",
      "    with open(txtFile,\"w\") as fout:\n",
      "        for para in paperSoup.find_all(\"p\"): \n",
      "           \n",
      "            # if it is bold font text, adorn the output text \n",
      "            strongContent = para.find(\"strong\")\n",
      "            if(strongContent != None):\n",
      "                fout.write(\"*******************************\\n\")\n",
      "                fout.write(\"%s\\n\" % para.text)\n",
      "                fout.write(\"*******************************\\n\")\n",
      "            # if it's plain string, write the output text simply\n",
      "            if(para.string != None): \n",
      "                fout.write(\"%s\\n\" % para.string)\n",
      "    \n",
      "    print(\"Completed processing file \" + txtFile + \"...\") "
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}