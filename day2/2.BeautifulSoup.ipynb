{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Python's BeautifulSoup Module"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "**Workshop on Web Scraping and Text Processing with Python**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**by Radhika Saksena, Princeton University, saksena@princeton.edu, radhika.saksena@gmail.com**\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Disclaimer: The code examples presented in this and subsequent handouts are for educational purposes only. Please seek advice from a legal expert about the legal implications of using this code for web scraping.\n",
      "*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. Extracting content from HTML files"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "1.1. Ex: Scraping the U.S. Congressional Record"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "**Problem Description**\n",
      "\n",
      "* The U.S. Congressional Record for the 113-th Congress is published daily at http://beta.congress.gov/congressional-record/browse-by-date. Our first BeautifulSoup example will involve extracting URLs for the \"Senate\" section of the daily Congressional record for May 2014 from this HTML table. \n",
      "\n",
      "\n",
      "* HTML tables are ubiquitous and the BeautifulSoup code that we'll see in this section can be adapted to work with other HTML tables. \n",
      "\n",
      "\n",
      "\n",
      "* For quick reference, a snippet of the source of the HTML table, at http://beta.congress.gov/congressional-record/113th-congress/browse-by-date, is shown below. \n",
      "\n",
      "\n",
      "* Note that you don't need to worry about indentation of the HTML/XML elements when using BeautifulSoup to parse the HTML/XML document. However, spaces do become significant if we are web scraping using regular expressions which we will cover later in this workshop.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " <table class=\"item_table sorting_table\">\n",
      "                <thead>\n",
      "                    <tr>\n",
      "                        <th scope=\"col\" class=\"browse_date\">Date and Issue No.</th>\n",
      "                        <th scope=\"col\" class=\"browse_daily\">Daily Digest</th>\n",
      "                        <th scope=\"col\" class=\"browse_senate\">Senate</th>\n",
      "                        <th scope=\"col\" class=\"browse_house\">House</th>\n",
      "                        <th scope=\"col\" class=\"browse_extensions\">Extensions of Remarks</th>\n",
      "                        <th scope=\"col\" class=\"browse_issue\">Entire Issue</th>\n",
      "                    </tr>\n",
      "                </thead>  \n",
      "                \n",
      "                \n",
      "                <tr>\n",
      "                    <td>May 30, 2014 - No. 83</td>\n",
      "                    <td><a href=\"/congressional-record/2014/05/30/\">D583-586</a></td>\n",
      "                    <td><a href=\"/congressional-record/2014/senate-section/page/S3317-3317\">S3317-3317</a></td>\n",
      "                    <td><a href=\"/congressional-record/2014/house-section/page/H5027-5065\">H5027-5065</a></td>\n",
      "                    <td><a href=\"/congressional-record/2014/extensions-of-remarks-section/page/E879-898\">E879-898</a></td>\n",
      "                    <td><a target=\"_blank\" href=\"/crec/2014/05/30/CREC-2014-05-30.pdf\">Entire Issue</a> (PDF)</td>\n",
      "                </tr>                    \n",
      "                <tr>\n",
      "                    <td>May 29, 2014 - No. 82</td>\n",
      "                    <td><a href=\"/congressional-record/2014/05/29/\">D574-582</a></td>\n",
      "                    <td>--</td>\n",
      "                    <td><a href=\"/congressional-record/2014/house-section/page/H4913-5025\">H4913-5025</a></td>\n",
      "                    <td><a href=\"/congressional-record/2014/extensions-of-remarks-section/page/E857-878\">E857-878</a></td>\n",
      "                    <td><a target=\"_blank\" href=\"/crec/2014/05/29/CREC-2014-05-29.pdf\">Entire Issue</a> (PDF)</td>\n",
      "                </tr>                    <tr>\n",
      "                    <td>May 28, 2014 - No. 81</td>\n",
      "                    <td><a href=\"/congressional-record/2014/05/28/\">D568-572</a></td>\n",
      "                    <td>--</td>\n",
      "                    <td><a href=\"/congressional-record/2014/house-section/page/H4839-4912\">H4839-4912</a></td>\n",
      "                     <td><a href=\"/congressional-record/2014/extensions-of-remarks-section/page/E841-856\">E841-856</a></td>\n",
      "                    <td><a target=\"_blank\" href=\"/crec/2014/05/28/CREC-2014-05-28.pdf\">Entire Issue</a> (PDF)</td>\n",
      "                </tr>                   \n",
      "                  ...\n",
      "</table>\n",
      "<table class=\"item_table sorting_table\">\n",
      "                <thead>\n",
      "                    <tr>\n",
      "                        <th scope=\"col\" class=\"browse_date\">Date and Issue No.</th>\n",
      "                        <th scope=\"col\" class=\"browse_daily\">Daily Digest</th>\n",
      "                        <th scope=\"col\" class=\"browse_senate\">Senate</th>\n",
      "                        <th scope=\"col\" class=\"browse_house\">House</th>\n",
      "                        <th scope=\"col\" class=\"browse_extensions\">Extensions of Remarks</th>\n",
      "                        <th scope=\"col\" class=\"browse_issue\">Entire Issue</th>\n",
      "                    </tr>\n",
      "                </thead>                    \n",
      "                <tr>\n",
      "                        <td>April 30, 2014 - No. 63</td>\n",
      "                        <td><a href=\"/congressional-record/2014/04/30/\">D440-448</a></td>\n",
      "                        <td><a href=\"/congressional-record/2014/senate-section/page/S2527-2558\">S2527-2558</a></td>\n",
      "                        <td><a href=\"/congressional-record/2014/house-section/page/H3295-3365\">H3295-3365</a></td>\n",
      "                        <td><a href=\"/congressional-record/2014/extensions-of-remarks-section/page/E6m29-649\">E629-649</a></td>\n",
      "                        <td><a target=\"_blank\" href=\"/crec/2014/04/30/CREC-2014-04-30.pdf\">Entire Issue</a> (PDF)</td>\n",
      "                 </tr>                    \n",
      "                 <tr>\n",
      "                        <td>April 29, 2014 - No. 62</td>\n",
      "                        <td><a href=\"/congressional-record/2014/04/29/\">D429-438</a></td>\n",
      "                        <td><a href=\"/congressional-record/2014/senate-section/page/S2427-2526\">S2427-2526</a></td>\n",
      "                        <td><a href=\"/congressional-record/2014/house-section/page/H3245-3294\">H3245-3294</a></td>\n",
      "                        <td><a href=\"/congressional-record/2014/extensions-of-remarks-section/page/E613-627\">E613-627</a></td>\n",
      "                        <td><a target=\"_blank\" href=\"/crec/2014/04/29/CREC-2014-04-29.pdf\">Entire Issue</a> (PDF)</td>\n",
      "                  </tr>                \n",
      "                  ...\n",
      "</table>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "**Some observations about the HTML table**\n",
      "\n",
      "* From the HTML source of the table, we see that the links to the Senate Congressional record are stored in elements marked up by the `<table>` tag. \n",
      "\n",
      "\n",
      "* Furthermore, there are multiple tables in the document, each corresponding to a specific month. Given a table element, there are many ways to determine the month to which it belongs. \n",
      "\n",
      "\n",
      "* The tables are listed in reverse chronological order.\n",
      "\n",
      "\n",
      "* For simplicity, our initial task is to extract information from the Congressional Record for May 2014, which is the first table on the HTML page.\n",
      "\n",
      "\n",
      "* Note that within the `<table>` element, the data is actually stored in the `<tr>` elements. The first `<tr>` element contains meta-data about the table such as column names, etc. and can be safely ignored. We need to extract substantive content from the second `<tr>` element onwards.\n",
      "\n",
      "\n",
      "* Also note that within each row element, the columns are marked up by `<td>` tags."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "First BeautifulSoup Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "* This Python code in ``getCongressionalRecordRows.py`` accesses the HTML page at http://beta.congress.gov/congressional-record/browse-by-date/ and constructs a BeautifulSoup object called `` soup `` from it. \n",
      "\n",
      "\n",
      "* Next, the ``find()`` method of the soup object is used to get a reference to the *first* `<table>` tag object. \n",
      "\n",
      "\n",
      "* Finally, the call to ``find_all()`` returns all the row elements of the table tag object in a list called ``childRows``. And we print out all these child rows (except the first row since it only contains table meta-data; also, remember that the first row has 0-index)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load getCongressionalRecordRows.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright 2014, Radhika S. Saksena (radhika dot saksena at gmail dot com)\n",
      "# Licensed under the Apache License, Version 2.0\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Web scraping and text processing with Python workshop\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "\n",
      "'''Print rows from a HTML table.'''\n",
      "\n",
      "URL = \"http://beta.congress.gov/congressional-record/browse-by-date/\"\n",
      "soup = BeautifulSoup(urllib2.urlopen(URL).read())\n",
      "\n",
      "table = soup.find(\"table\")\n",
      "\n",
      "childRows = table.find_all(\"tr\")\n",
      "for i in range(1,len(childRows)):\n",
      "    print(childRows[i])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "* It is clear from the \ufb01rst few lines of the\n",
      "output from running the code in ``getCongressionalRecordRows.py``, that the Senate \n",
      "section information is in the third column (index = 2) in the ``href`` attribute of the\n",
      "``<a>`` tag. Furthermore, it would be useful to extract the labels of these Senate section links \"S189-265\" , \"S87-S188\"\n",
      "and so on; these labels are available as the text content of the ``<a>`` tag. \n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "Solution - I"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "Now, moving forward on the task we have set, let's extend the code in ``getCongressionalRecordRows.py`` to access the links to the Senate section."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load getCongressionalRecordLinks.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright 2014, Radhika S. Saksena (radhika dot saksena at gmail dot com)\n",
      "# Licensed under the Apache License, Version 2.0\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Web scraping and text processing with Python workshop\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "\n",
      "'''Extract and print link information from the Senate Section column.'''\n",
      "\n",
      "URL = \"http://beta.congress.gov/congressional-record/browse-by-date/\"\n",
      "soup = BeautifulSoup(urllib2.urlopen(URL).read())\n",
      "baseURL = \"http://beta.congress.gov/\"\n",
      "\n",
      "table = soup.find(\"table\")\n",
      "\n",
      "childRows = table.find_all(\"tr\")\n",
      "\n",
      "for childRow in childRows[1:]:\n",
      "    childColumns = childRow.find_all(\"td\")\n",
      "    try:\n",
      "        print(\"%s, %s%s\\n\" \\\n",
      "                % (childColumns[2].find(\"a\").text,\\\n",
      "                baseURL,childColumns[2].find(\"a\").get(\"href\")))\n",
      "    except:\n",
      "        pass\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "* The code in ``getCongressionalRecordLinks.py``, first, makes use of the ``find_all()`` method to get a list of all the column tag objects (HTML tag `<td>` ) in a row. \n",
      "\n",
      "\n",
      "* Then the list index (``[2]`` ) is used to access the third column\n",
      "tag object in this list corresponding to the Senate section. A reference to the child ``<a>`` tag of the column is obtained by using ``find()`` again.\n",
      "\n",
      "\n",
      "* Finally, the label of the hyperlink is accessed from the text property of the ``<a>`` tag object and the URL of the\n",
      "Senate section is accessed from the ``href`` attribute of the ``<a>`` tag object. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Solution - II"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In the Python code that we have seen so far, the ``find()`` and ``find_all()`` methods were used to \ufb01nd speci\ufb01c HTML *tags*. \n",
      "\n",
      "\n",
      "* The ``find()`` and ``find_all()`` methods can also be used to search for speci\ufb01c *attributes*. For example, in order to extract the Senate section link, we could search for a child element with the ``href`` attribute instead of search for an ``<a>`` tag. The code in ``getCongressionalRecordlinks_attr.py`` demonstrates the use of ``find()`` to find elements by attributes rather than tag names. \n",
      "\n",
      "\n",
      "* Note that this form of ``find()``/``find_all()`` which allows the HTML document to be searched for a particular attribute makes use of regular expressions (Python\u2019s ``re`` module) and we will see more of regular expressions in subsequent material."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load getCongressionalRecordLinks_attr.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright 2014, Radhika S. Saksena (radhika dot saksena at gmail dot com)\n",
      "# Licensed under the Apache License, Version 2.0\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Web scraping and text processing with Python workshop\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import codecs\n",
      "import re\n",
      "\n",
      "'''Extract and print link information from the Senate Section column.'''\n",
      "\n",
      "baseURL = \"http://beta.congress.gov\"\n",
      "#URL = \"http://beta.congress.gov/congressional-record/browse-by-date/\"\n",
      "URL = baseURL + \"/congressional-record/browse-by-date/\"\n",
      "soup = BeautifulSoup(urllib2.urlopen(URL).read())\n",
      "\n",
      "table = soup.find(\"table\")\n",
      "\n",
      "childRows = table.find_all(\"tr\")\n",
      "\n",
      "for childRow in childRows[1:]:\n",
      "    childColumns = childRow.find_all(\"td\")\n",
      "    try:\n",
      "        print(\"Senate section link: %s%s\\n\" \\\n",
      "        % (baseURL,\\\n",
      "        childColumns[2].find(href=re.compile(\".*\")).get(\"href\")))\n",
      "    except:\n",
      "        pass\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3317-3317\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3315-3315\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3313-3313\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3245-3311\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3195-3244\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3151-3194\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3149-3149\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S3047-3147\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2981-3045\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2923-2980\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2889-2922\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2831-2888\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2741-2829\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2681-2740\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2625-2679\n",
        "\n",
        "Senate section link: http://beta.congress.gov/congressional-record/2014/senate-section/page/S2571-2623\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "2. Extracting content from XML files"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.1. Ex: Scraping U.S. Senators' Info"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Problem Description**<br/>\n",
      "\n",
      "* Consider the XML document available at http://www.senate.gov/general/contact_information/senators_cfm.xml. This document describes the 100 members of the U.S. senate including information such as \ufb01rst name, last name, party, state, address, phone, bioguide_id, etc. \n",
      "\n",
      "\n",
      "* A snippet of the XML corresponding to the first two U.S. Senate members is listed below.\n",
      "\n",
      "\n",
      "* The task in this section is to use a Python script to: <br/>\n",
      "    * download this XML \ufb01le from the Senate website. <br/>\n",
      "    * parse the XML \ufb01le to \ufb01nd the \ufb01rst name, last name, state and party of all the US senators listed there. <br/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "<contact_information>\n",
      "    <member>\n",
      "        <member_full>Alexander (R-TN)</member_full>\n",
      "        <last_name>Alexander</last_name>\n",
      "        <first_name>Lamar</first_name>\n",
      "        <party>R</party>\n",
      "        <state>TN</state>\n",
      "        <address>\n",
      "        455 DIRKSEN SENATE OFFICE BUILDING WASHINGTON DC 20510\n",
      "        </address>\n",
      "        <phone>(202) 224-4944</phone>\n",
      "        <email>\n",
      "        http://www.alexander.senate.gov/public/index.cfm?p=Email\n",
      "        </email>\n",
      "        <website>http://www.alexander.senate.gov/</website>\n",
      "        <class>Class II</class>\n",
      "        <bioguide_id>A000360</bioguide_id>\n",
      "    </member>\n",
      "    <member>\n",
      "        <member_full>Ayotte (R-NH)</member_full>\n",
      "        <last_name>Ayotte</last_name>\n",
      "        <first_name>Kelly</first_name>\n",
      "        <party>R</party>\n",
      "        <state>NH</state>\n",
      "        <address>\n",
      "        144 RUSSELL SENATE OFFICE BUILDING WASHINGTON DC 20510\n",
      "        </address>\n",
      "        <phone>(202) 224-3324</phone>\n",
      "        <email>http://www.ayotte.senate.gov/?p=contact</email>\n",
      "        <website>http://www.ayotte.senate.gov</website>\n",
      "        <class>Class III</class>\n",
      "        <bioguide_id>A000368</bioguide_id>\n",
      "    </member>\n",
      "    ...\n",
      "</contact_information>\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "**Some observations about the XML document** <br/>\n",
      "\n",
      "* Given the URL of the XML document, it can be retrieved using Python\u2019s ``urllib2`` module, as we have seen previously.\n",
      "\n",
      "\n",
      "* The XML document  contains a list of member tags each of which\n",
      "has nested tags for the the member\u2019s \ufb01rst name, last name, party, state, etc.\n",
      "\n",
      "\n",
      "* Since, this is XML, it is reasonable to assume that each of the 100 member elements will consistently\n",
      "have the following child tags: first_name , last_name , party , state . These tags contain the\n",
      "substantive information we are after."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Solution - I"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load senators.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright 2014, Radhika S. Saksena (radhika dot saksena at gmail dot com)\n",
      "# Licensed under the Apache License, Version 2.0\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Web scraping and text processing with Python workshop\n",
      "\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "\n",
      "'''This Python script reads Senators' contact information from\n",
      "   http://www.senate.gov/general/contact_information/senators_cfm.xml.\n",
      "   It parses the Senator first and last names, party and state\n",
      "   and prints this information to screen for all the Senators.'''\n",
      "\n",
      "# instantiate pandas DataFrame to store scraped Senator information\n",
      "senatorsDF = pd.DataFrame(columns = [\"first_name\",\"last_name\",\"party\",\"state\"])\n",
      "\n",
      "# Download the XML document from Senate website and create a BeautifulSoup\n",
      "# object\n",
      "url = \"http://www.senate.gov/general/contact_information/senators_cfm.xml\"\n",
      "xml = urllib2.urlopen(url).read()\n",
      "soup = BeautifulSoup(xml)\n",
      "\n",
      "#print soup.prettify()\n",
      "\n",
      "print \"List of Senators and affiliations obtained from www.senate.gov:\"\n",
      "\n",
      "# Find all the member tag objects in the XML document using find_all()\n",
      "for member in soup.find_all(\"member\"):\n",
      "\n",
      "    first_name_str = member.find(\"first_name\").string\n",
      "    last_name_str = member.find(\"last_name\").string\n",
      "    party_str = member.find(\"party\").string\n",
      "    state_str = member.find(\"state\").string\n",
      "    senatorsDF = senatorsDF.append({\"first_name\":first_name_str, \\\n",
      "                        \"last_name\":last_name_str, \\\n",
      "                        \"party\":party_str, \\\n",
      "                        \"state\":state_str},ignore_index=True)\n",
      "\n",
      "# Print dataframe to screen\n",
      "print(\"{0:10s}\\t,{1:10s}\\t,{2:10s}\\t,{3:10s}\".\n",
      "        format(\"first_name\",\n",
      "                \"last_name\",\n",
      "                \"party\",\n",
      "                 \"state\"))\n",
      "for i,row in senatorsDF[1:20].iterrows():\n",
      "     print(\"{0:10s}\\t,{1:10s}\\t,{2:10s}\\t,{3:10s}\".\n",
      "             format(row['first_name'],\n",
      "                    row['last_name'],\n",
      "                    row['party'],\n",
      "                    row['state']))\n",
      "\n",
      "# Another quick way to Print dataframe to screen\n",
      "# print(senatorsDF.head(20))\n",
      "\n",
      "# Write dataframe to csv file\n",
      "senatorsDF.to_csv(\"senatorsPA.csv\",sep=\",\",index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "List of Senators and affiliations obtained from www.senate.gov:\n",
        "first_name\t,last_name \t,party     \t,state     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kelly     \t,Ayotte    \t,R         \t,NH        \n",
        "Tammy     \t,Baldwin   \t,D         \t,WI        \n",
        "John      \t,Barrasso  \t,R         \t,WY        \n",
        "Mark      \t,Begich    \t,D         \t,AK        \n",
        "Michael F.\t,Bennet    \t,D         \t,CO        \n",
        "Richard   \t,Blumenthal\t,D         \t,CT        \n",
        "Roy       \t,Blunt     \t,R         \t,MO        \n",
        "Cory A.   \t,Booker    \t,D         \t,NJ        \n",
        "John      \t,Boozman   \t,R         \t,AR        \n",
        "Barbara   \t,Boxer     \t,D         \t,CA        \n",
        "Sherrod   \t,Brown     \t,D         \t,OH        \n",
        "Richard   \t,Burr      \t,R         \t,NC        \n",
        "Maria     \t,Cantwell  \t,D         \t,WA        \n",
        "Benjamin L.\t,Cardin    \t,D         \t,MD        \n",
        "Thomas R. \t,Carper    \t,D         \t,DE        \n",
        "Robert P., Jr.\t,Casey     \t,D         \t,PA        \n",
        "Saxby     \t,Chambliss \t,R         \t,GA        \n",
        "Daniel    \t,Coats     \t,R         \t,IN        \n",
        "Tom       \t,Coburn    \t,R         \t,OK        \n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "* In the Python code in ``senators.py``, we start by importing the ``urllib2``, ``BeautifulSoup`` and ``pandas`` modules. \n",
      "\n",
      "\n",
      "* Given the URL of the XML document, it is retrieved and stored in the string variable ``xml``. \n",
      "\n",
      "\n",
      "* A ``BeautifulSoup`` object called ``soup`` is created from ``xml`` and ``soup`` is then used for content extraction.\n",
      "\n",
      "\n",
      "* BeautifulSoup\u2019s ``find_all()`` method is invoked on ``soup`` to obtain all the ``<member>`` tags. These tag objects are stored in a list variable named ``members``. \n",
      "\n",
      "\n",
      "* Then, in the ``for`` loop over each member object in the ``members`` list, the ``find()`` method is invoked to obtain the nested child tag objects corresponding to the first name, last name, party and state. \n",
      "\n",
      "\n",
      "* Finally, the string content of these child tag objects is extracted by referencing their ``string`` property. Note that ``find()`` is a *method* provided by the tag object while ``string`` (note the lack of parentheses) is a *property* of the tag object. \n",
      "\n",
      "\n",
      "* The content extracted from the XML document is stored in a pandas DataFrame. In addition to printing the pandas DataFrame to screen (using the statement ``print(senatorsDF.head(20))``), we have also used the ``to_csv()`` method to write the data to a csv file. This can now easily be imported in to R and Excel."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Solution - II"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Since, we are dealing with XML files, we expect each of the ``member`` elements to contain the first name, last name, party and state sub-elements. In this case, it also makes sense to use an alternative method of accessing child tags: instead of invoking the ``find()`` method on the ``member`` tag object, we can reference the different child tags as properties of the ``member`` tag object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load senatorsProp.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright 2014, Radhika S. Saksena (radhika dot saksena at gmail dot com)\n",
      "# Licensed under the Apache License, Version 2.0\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Web scraping and text processing with Python workshop\n",
      "\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "\n",
      "'''This Python script reads Senators' contact information from\n",
      "   http://www.senate.gov/general/contact_information/senators_cfm.xml.\n",
      "   It parses the first and last names, party and state\n",
      "   and prints this information to screen for all the Senators.'''\n",
      "\n",
      "# instantiate pandas DataFrame to store scraped Senator information\n",
      "senatorsDF = pd.DataFrame(columns = [\"first_name\",\"last_name\",\"party\",\"state\"])\n",
      "\n",
      "# Download the XML document from Senate website and create a BeautifulSoup\n",
      "# object\n",
      "url = \"http://www.senate.gov/general/contact_information/senators_cfm.xml\"\n",
      "xml = urllib2.urlopen(url).read()\n",
      "soup = BeautifulSoup(xml)\n",
      "\n",
      "#print soup.prettify()\n",
      "\n",
      "print \"List of Senators and affiliations obtained from www.senate.gov:\"\n",
      "\n",
      "# Find all the member tag objects in the XML document using find_all()\n",
      "for member in soup.find_all(\"member\"):\n",
      "\n",
      "    first_name_str = member.first_name.string\n",
      "    last_name_str = member.last_name.string\n",
      "    party_str = member.party.string\n",
      "    state_str = member.state.string\n",
      "    senatorsDF = senatorsDF.append({\"first_name\":first_name_str, \\\n",
      "                        \"last_name\":last_name_str, \\\n",
      "                        \"party\":party_str, \\\n",
      "                        \"state\":state_str},ignore_index=True)\n",
      "\n",
      "# Print dataframe to screen\n",
      "print(\"{0:10s}\\t,{1:10s}\\t,{2:10s}\\t,{3:10s}\".\n",
      "        format(\"first_name\",\n",
      "                \"last_name\",\n",
      "                \"party\",\n",
      "                 \"state\"))\n",
      "for i,row in senatorsDF[1:20].iterrows():\n",
      "     print(\"{0:10s}\\t,{1:10s}\\t,{2:10s}\\t,{3:10s}\".\n",
      "             format(row['first_name'],\n",
      "                    row['last_name'],\n",
      "                    row['party'],\n",
      "                    row['state']))\n",
      "\n",
      "# Another quick way to Print dataframe to screen\n",
      "# print(senatorsDF.head(20))\n",
      "\n",
      "# Write dataframe to csv file\n",
      "senatorsDF.to_csv(\"senatorsPA.csv\",sep=\",\",index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "List of Senators and affiliations obtained from www.senate.gov:\n",
        "first_name\t,last_name \t,party     \t,state     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kelly     \t,Ayotte    \t,R         \t,NH        \n",
        "Tammy     \t,Baldwin   \t,D         \t,WI        \n",
        "John      \t,Barrasso  \t,R         \t,WY        \n",
        "Mark      \t,Begich    \t,D         \t,AK        \n",
        "Michael F.\t,Bennet    \t,D         \t,CO        \n",
        "Richard   \t,Blumenthal\t,D         \t,CT        \n",
        "Roy       \t,Blunt     \t,R         \t,MO        \n",
        "Cory A.   \t,Booker    \t,D         \t,NJ        \n",
        "John      \t,Boozman   \t,R         \t,AR        \n",
        "Barbara   \t,Boxer     \t,D         \t,CA        \n",
        "Sherrod   \t,Brown     \t,D         \t,OH        \n",
        "Richard   \t,Burr      \t,R         \t,NC        \n",
        "Maria     \t,Cantwell  \t,D         \t,WA        \n",
        "Benjamin L.\t,Cardin    \t,D         \t,MD        \n",
        "Thomas R. \t,Carper    \t,D         \t,DE        \n",
        "Robert P., Jr.\t,Casey     \t,D         \t,PA        \n",
        "Saxby     \t,Chambliss \t,R         \t,GA        \n",
        "Daniel    \t,Coats     \t,R         \t,IN        \n",
        "Tom       \t,Coburn    \t,R         \t,OK        \n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}